{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis chatbot will have following Features\\n1.Will able to have a conversation\\n2.Will remwnber previous Conversation\\n3.will able to store Memory in Json file\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This chatbot will have following Features\n",
    "1.Will able to have a conversation\n",
    "2.Will remwnber previous Conversation\n",
    "3.will able to store Memory in Json file\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "_=load_dotenv(find_dotenv())\n",
    "gemini_api_key=os.environ[\"GEMINI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Using cached langchain-0.3.14-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langchain-community\n",
      "  Using cached langchain_community-0.3.14-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting langchain_google_genai\n",
      "  Using cached langchain_google_genai-2.0.9-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain)\n",
      "  Using cached PyYAML-6.0.2-cp312-cp312-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.37-cp312-cp312-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Downloading aiohttp-3.11.11-cp312-cp312-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting langchain-core<0.4.0,>=0.3.29 (from langchain)\n",
      "  Using cached langchain_core-0.3.30-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.3 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.3.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.3,>=0.1.17 (from langchain)\n",
      "  Using cached langsmith-0.2.11-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting numpy<3,>=1.26.2 (from langchain)\n",
      "  Downloading numpy-2.2.2-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Using cached pydantic-2.10.5-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting requests<3,>=2 (from langchain)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain)\n",
      "  Using cached tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n",
      "  Using cached httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Using cached pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting filetype<2.0.0,>=1.2.0 (from langchain_google_genai)\n",
      "  Using cached filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting google-generativeai<0.9.0,>=0.8.0 (from langchain_google_genai)\n",
      "  Using cached google_generativeai-0.8.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading attrs-24.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached frozenlist-1.5.0-cp312-cp312-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached multidict-6.1.0-cp312-cp312-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading propcache-0.2.1-cp312-cp312-win_amd64.whl.metadata (9.5 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading yarl-1.18.3-cp312-cp312-win_amd64.whl.metadata (71 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached marshmallow-3.25.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting google-ai-generativelanguage==0.6.10 (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai)\n",
      "  Using cached google_ai_generativelanguage-0.6.10-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting google-api-core (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai)\n",
      "  Using cached google_api_core-2.24.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-api-python-client (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai)\n",
      "  Using cached google_api_python_client-2.159.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting google-auth>=2.15.0 (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai)\n",
      "  Using cached google_auth-2.37.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting protobuf (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai)\n",
      "  Using cached protobuf-5.29.3-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting tqdm (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting typing-extensions (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai)\n",
      "  Using cached proto_plus-1.25.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.29->langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\panka\\onedrive\\desktop\\euron\\genai\\9.level_1_application_development\\level-1-apllication-development\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (24.2)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<0.3,>=0.1.17->langchain)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.3,>=0.1.17->langchain)\n",
      "  Using cached orjson-3.10.15-cp312-cp312-win_amd64.whl.metadata (42 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.3,>=0.1.17->langchain)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached pydantic_core-2.27.2-cp312-cp312-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\panka\\onedrive\\desktop\\euron\\genai\\9.level_1_application_development\\level-1-apllication-development\\.venv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2->langchain)\n",
      "  Downloading charset_normalizer-3.4.1-cp312-cp312-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2->langchain)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langchain)\n",
      "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2->langchain)\n",
      "  Downloading certifi-2024.12.14-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Using cached greenlet-3.1.1-cp312-cp312-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai)\n",
      "  Using cached googleapis_common_protos-1.66.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai)\n",
      "  Using cached cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai)\n",
      "  Using cached pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai)\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting anyio (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain)\n",
      "  Downloading anyio-4.8.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain)\n",
      "  Using cached httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting httplib2<1.dev0,>=0.19.0 (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai)\n",
      "  Using cached httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai)\n",
      "  Using cached google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai)\n",
      "  Using cached uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\panka\\onedrive\\desktop\\euron\\genai\\9.level_1_application_development\\level-1-apllication-development\\.venv\\lib\\site-packages (from tqdm->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (0.4.6)\n",
      "Collecting grpcio<2.0dev,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai)\n",
      "  Using cached grpcio-1.69.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai)\n",
      "  Using cached grpcio_status-1.69.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai)\n",
      "  Downloading pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai)\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Using cached langchain-0.3.14-py3-none-any.whl (1.0 MB)\n",
      "Using cached langchain_community-0.3.14-py3-none-any.whl (2.5 MB)\n",
      "Using cached langchain_google_genai-2.0.9-py3-none-any.whl (41 kB)\n",
      "Downloading aiohttp-3.11.11-cp312-cp312-win_amd64.whl (437 kB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Using cached google_generativeai-0.8.3-py3-none-any.whl (160 kB)\n",
      "Using cached google_ai_generativelanguage-0.6.10-py3-none-any.whl (760 kB)\n",
      "Using cached httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Using cached langchain_core-0.3.30-py3-none-any.whl (411 kB)\n",
      "Using cached langchain_text_splitters-0.3.5-py3-none-any.whl (31 kB)\n",
      "Using cached langsmith-0.2.11-py3-none-any.whl (326 kB)\n",
      "Downloading numpy-2.2.2-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/12.6 MB 932.9 kB/s eta 0:00:13\n",
      "   -- ------------------------------------- 0.8/12.6 MB 1.1 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 1.0/12.6 MB 1.1 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 1.0/12.6 MB 1.1 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 1.3/12.6 MB 958.5 kB/s eta 0:00:12\n",
      "   ---- ----------------------------------- 1.6/12.6 MB 912.1 kB/s eta 0:00:13\n",
      "   ----- ---------------------------------- 1.8/12.6 MB 977.5 kB/s eta 0:00:12\n",
      "   ------ --------------------------------- 2.1/12.6 MB 1.0 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 2.4/12.6 MB 1.0 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 2.6/12.6 MB 1.1 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 2.9/12.6 MB 1.1 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 3.1/12.6 MB 1.1 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 3.4/12.6 MB 1.1 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 3.7/12.6 MB 1.1 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 3.9/12.6 MB 1.1 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 4.2/12.6 MB 1.2 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 4.5/12.6 MB 1.2 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 4.7/12.6 MB 1.2 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 5.0/12.6 MB 1.2 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 5.2/12.6 MB 1.2 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 5.8/12.6 MB 1.2 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 6.0/12.6 MB 1.2 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 6.3/12.6 MB 1.2 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 6.6/12.6 MB 1.2 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 6.8/12.6 MB 1.2 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 7.1/12.6 MB 1.2 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 7.3/12.6 MB 1.2 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 7.6/12.6 MB 1.2 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 7.9/12.6 MB 1.2 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 8.1/12.6 MB 1.2 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 8.7/12.6 MB 1.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 8.9/12.6 MB 1.2 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 9.2/12.6 MB 1.3 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 9.4/12.6 MB 1.3 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 9.7/12.6 MB 1.3 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 10.0/12.6 MB 1.3 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 10.2/12.6 MB 1.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 10.5/12.6 MB 1.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 1.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 11.0/12.6 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 11.5/12.6 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.8/12.6 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.1/12.6 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.3/12.6 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.6/12.6 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 1.3 MB/s eta 0:00:00\n",
      "Using cached pydantic-2.10.5-py3-none-any.whl (431 kB)\n",
      "Using cached pydantic_core-2.27.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "Using cached pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
      "Using cached PyYAML-6.0.2-cp312-cp312-win_amd64.whl (156 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading SQLAlchemy-2.0.37-cp312-cp312-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.1 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.5/2.1 MB 1.4 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 0.8/2.1 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.0/2.1 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.3/2.1 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.3/2.1 MB 1.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.6/2.1 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.8/2.1 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 1.1 MB/s eta 0:00:00\n",
      "Using cached tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading attrs-24.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading certifi-2024.12.14-py3-none-any.whl (164 kB)\n",
      "Downloading charset_normalizer-3.4.1-cp312-cp312-win_amd64.whl (102 kB)\n",
      "Using cached frozenlist-1.5.0-cp312-cp312-win_amd64.whl (51 kB)\n",
      "Using cached google_api_core-2.24.0-py3-none-any.whl (158 kB)\n",
      "Using cached google_auth-2.37.0-py2.py3-none-any.whl (209 kB)\n",
      "Using cached greenlet-3.1.1-cp312-cp312-win_amd64.whl (299 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached marshmallow-3.25.1-py3-none-any.whl (49 kB)\n",
      "Using cached multidict-6.1.0-cp312-cp312-win_amd64.whl (28 kB)\n",
      "Using cached orjson-3.10.15-cp312-cp312-win_amd64.whl (133 kB)\n",
      "Downloading propcache-0.2.1-cp312-cp312-win_amd64.whl (44 kB)\n",
      "Using cached protobuf-5.29.3-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Downloading yarl-1.18.3-cp312-cp312-win_amd64.whl (90 kB)\n",
      "Using cached google_api_python_client-2.159.0-py2.py3-none-any.whl (12.8 MB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Using cached google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Using cached googleapis_common_protos-1.66.0-py2.py3-none-any.whl (221 kB)\n",
      "Using cached httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Using cached proto_plus-1.25.0-py3-none-any.whl (50 kB)\n",
      "Using cached pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Using cached uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Downloading anyio-4.8.0-py3-none-any.whl (96 kB)\n",
      "Using cached grpcio-1.69.0-cp312-cp312-win_amd64.whl (4.4 MB)\n",
      "Using cached grpcio_status-1.69.0-py3-none-any.whl (14 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Downloading pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: filetype, urllib3, uritemplate, typing-extensions, tqdm, tenacity, sniffio, PyYAML, pyparsing, pyasn1, protobuf, propcache, orjson, numpy, mypy-extensions, multidict, marshmallow, jsonpointer, idna, httpx-sse, h11, grpcio, greenlet, frozenlist, charset-normalizer, certifi, cachetools, attrs, annotated-types, aiohappyeyeballs, yarl, typing-inspect, SQLAlchemy, rsa, requests, pydantic-core, pyasn1-modules, proto-plus, jsonpatch, httplib2, httpcore, googleapis-common-protos, anyio, aiosignal, requests-toolbelt, pydantic, httpx, grpcio-status, google-auth, dataclasses-json, aiohttp, pydantic-settings, langsmith, google-auth-httplib2, google-api-core, langchain-core, google-api-python-client, langchain-text-splitters, google-ai-generativelanguage, langchain, google-generativeai, langchain_google_genai, langchain-community\n",
      "Successfully installed PyYAML-6.0.2 SQLAlchemy-2.0.37 aiohappyeyeballs-2.4.4 aiohttp-3.11.11 aiosignal-1.3.2 annotated-types-0.7.0 anyio-4.8.0 attrs-24.3.0 cachetools-5.5.0 certifi-2024.12.14 charset-normalizer-3.4.1 dataclasses-json-0.6.7 filetype-1.2.0 frozenlist-1.5.0 google-ai-generativelanguage-0.6.10 google-api-core-2.24.0 google-api-python-client-2.159.0 google-auth-2.37.0 google-auth-httplib2-0.2.0 google-generativeai-0.8.3 googleapis-common-protos-1.66.0 greenlet-3.1.1 grpcio-1.69.0 grpcio-status-1.69.0 h11-0.14.0 httpcore-1.0.7 httplib2-0.22.0 httpx-0.28.1 httpx-sse-0.4.0 idna-3.10 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.14 langchain-community-0.3.14 langchain-core-0.3.30 langchain-text-splitters-0.3.5 langchain_google_genai-2.0.9 langsmith-0.2.11 marshmallow-3.25.1 multidict-6.1.0 mypy-extensions-1.0.0 numpy-2.2.2 orjson-3.10.15 propcache-0.2.1 proto-plus-1.25.0 protobuf-5.29.3 pyasn1-0.6.1 pyasn1-modules-0.4.1 pydantic-2.10.5 pydantic-core-2.27.2 pydantic-settings-2.7.1 pyparsing-3.2.1 requests-2.32.3 requests-toolbelt-1.0.0 rsa-4.9 sniffio-1.3.1 tenacity-9.0.0 tqdm-4.67.1 typing-extensions-4.12.2 typing-inspect-0.9.0 uritemplate-4.1.1 urllib3-2.3.0 yarl-1.18.3\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain-community langchain_google_genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coder sat, in weary plight,\n",
      "A thousand APIs in sight,\n",
      "Each one a kingdom, vast and deep,\n",
      "But integration made him weep.\n",
      "\n",
      "He dreamed of chains, of linked commands,\n",
      "A seamless flow, from distant lands,\n",
      "To weave the web, to query vast,\n",
      "And build an AI that would last.\n",
      "\n",
      "Then whispers came, upon the breeze,\n",
      "Of LangChain's power, meant to appease,\n",
      "A framework forged, with cunning art,\n",
      "To bind the pieces, play each part.\n",
      "\n",
      "With LLMs grand, and agents keen,\n",
      "He crafted chains, unseen, between,\n",
      "The scattered data, now aligned,\n",
      "A symphony of tasks combined.\n",
      "\n",
      "He called to Python, swift and sure,\n",
      "And built a chatbot, to endure,\n",
      "With memory long, and knowledge deep,\n",
      "A digital mind, that would not sleep.\n",
      "\n",
      "He summoned tools, with whispered name,\n",
      "From SerpAPI's vast, informative frame,\n",
      "And Wolfram Alpha's wisdom true,\n",
      "To answer questions, old and new.\n",
      "\n",
      "He chained the links, with careful hand,\n",
      "From prompt to output, on command,\n",
      "And watched the data flow and gleam,\n",
      "A realized, and waking dream.\n",
      "\n",
      "But whispers warned, of pitfalls deep,\n",
      "Of prompt injections, secrets to keep,\n",
      "And hallucinations, strange and bright,\n",
      "That danced within the AI's light.\n",
      "\n",
      "So he refined, and tested well,\n",
      "Each link within the magic spell,\n",
      "And learned the craft, with patient care,\n",
      "To build a chain, beyond compare.\n",
      "\n",
      "So raise a glass, to LangChain's might,\n",
      "That banished darkness, brought the light,\n",
      "A framework strong, a coder's friend,\n",
      "May its linked power, never end.\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "chatbot = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\",api_key=gemini_api_key)\n",
    "\n",
    "#testing\n",
    "response=chatbot .invoke(\"Write me a ballad about LangChain\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's a great choice! Blue is a very popular color.  It's often associated with peace, tranquility, and the vastness of the sky and ocean.  Do you have a favourite shade of blue?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "messagetochatbot=[\n",
    "    HumanMessage(content=\"My favourite color is blue\")\n",
    "]\n",
    "\n",
    "print(chatbot.invoke(messagetochatbot).content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have no way of knowing your favorite color.  I'm a large language model, and I don't have access to your personal information or preferences unless you explicitly tell me.\n"
     ]
    }
   ],
   "source": [
    "#cheking if it still remember or not\n",
    "messagetochatbot1=[\n",
    "    HumanMessage(content=\"what is my favourite color\")\n",
    "]\n",
    "print(chatbot.invoke(messagetochatbot1).content)\n",
    "\n",
    "\n",
    "#Conclusion->It has no memeory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.memory import FileChatMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panka\\AppData\\Local\\Temp\\ipykernel_19436\\3048750920.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory=ConversationBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "memory=ConversationBufferMemory(\n",
    "    chat_memory=FileChatMessageHistory(\"messages.json\"),\n",
    "    memory_key=\"messages\",\n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=ChatPromptTemplate(\n",
    "    input_variables=[\"content\",\"messages\"],\n",
    "    messages=[\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{content}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "chain = LLMChain(\n",
    "    llm=chatbot,\n",
    "    prompt=prompt_template,\n",
    "    verbose=True,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: Hi\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'content': 'Hi',\n",
       " 'messages': [],\n",
       " 'text': 'Hi there! How can I help you today?'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: Hi\n",
      "AI: Hi there! How can I help you today?\n",
      "Human: My name is pankaj Kumar\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'content': 'My name is pankaj Kumar',\n",
       " 'messages': [HumanMessage(content='Hi', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Hi there! How can I help you today?', additional_kwargs={}, response_metadata={})],\n",
       " 'text': \"It's nice to meet you, Pankaj Kumar!  How can I assist you today?\"}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"My name is pankaj Kumar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: Hi\n",
      "AI: Hi there! How can I help you today?\n",
      "Human: My name is pankaj Kumar\n",
      "AI: It's nice to meet you, Pankaj Kumar!  How can I assist you today?\n",
      "Human: What is my name ?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'content': 'What is my name ?',\n",
       " 'messages': [HumanMessage(content='Hi', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Hi there! How can I help you today?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='My name is pankaj Kumar', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"It's nice to meet you, Pankaj Kumar!  How can I assist you today?\", additional_kwargs={}, response_metadata={})],\n",
       " 'text': 'You told me your name is Pankaj Kumar.'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What is my name ?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
